---
title: Example Title
draft: True
tags:
- example-tag
---

`please Write some good interview questions surrounding logistic regression (for a machine learning engineer role)`

---

mock interviews, behavioural prep, brushing up on your projects so you know what to talk about haha, but if you're going for the canva ML role then i'd advise:

- going over basic training stuff, so train test split, how would you combat under-represented classes
- potential ai bias stuff
- a read on recommender systems

---


Naw. 
DON'T CHANGE QUESTION NAMES

```
AWS
SVM,
LOG REGRESSION,¬†
GIT,¬†
GO. -> PUBLISH. (quant, options) Post to hackernews. Make the markdown beautiful map.¬†
Leetcodes.**
```

Resolve: 
- INDEX: Launch
- README: About this book
	- 50-50 train, test split. As in you can expect to spend half of this book learning things and half being tested on them. 
- Requirements.txt
Everything from AFF notes

> [!check] The idea üóùÔ∏è
> The idea is to...



- [ ] QUESTIONS ARE NOW ##### HASHTAGS
- [ ] ADD THE THING AT THE START OF EACH PAGE W/ TAGS AND TITLE
- [ ] Figure out how to get *coloured CMU* serif on website
- [ ] Figure out to render LaTeX properly. 
- [ ] https://quartz.jzhao.xyz/features/callouts
- [ ] Now just need coloured text
- [ ] ML stickers. 
https://youtu.be/FpuiovvSPYc?si=t3RNfQirnGASEVUt
+ quant, 

Follow the pointers, edit in source mode. 

make it more streamlined. Make the structure make more sense - simpler
Add Tags after. 
![[Pasted image 20231206073026.png]]


---

**Questions**
- Python error types
- LC 32
- SELF LEARNING
- **casse study. ZOom‚Äôs blur feature. How would you implement this?**
- What are the knobs - parameters
- information theory.
DSX: df.to_csv
Pd.read_csv
DSX: when to use dataframe vs a tensor
DSX:

  
One day I will release this book w/ all my mentors undeserved.

remember that time you told me to start w/ the naive solution then optiimse. That really stuck w/ me

  

No point grinding that deeply to make a stable million dollars, when you could just start a business high volatility and make an irrationally large sum of money

  
  
  

2 years of like no life occuring, no learning, no exposure to anything. then i went into work, into uni¬†

  

[https://quartz.jzhao.xyz/setting-up-your-GitHub-repository](https://quartz.jzhao.xyz/setting-up-your-GitHub-repository)

  
  

Viet w/ moliiiii

DSX:¬†

  

No moli (she‚Äôs the best, eating dinner w/ her in vietnam, the best, but also, this stuff is the best. Get to get padi to code) , but:¬†

- DSX!!!!
    

  
  
  

Coding fast. Ohhh Anthony. Begin. Don‚Äôt talk shit

Grinding w/ VIc¬†

Writing corporate code: DSX

My biggest obstacles in my coding career: myself. Caspar. But now I‚Äôm coding for a company rn. So grateful. Projects. Kaggles .Focus.¬†

Mst use python. Gogogo Mew.¬†

  
  

-   
    
- Dataframes, coding this automated data extracting thing, thinking actual good, modular, readable corporate code.¬†
    

  
  
  
  

DSX Git

pretrain/post-train

DSX: Recall

DSX: quick explain this error message.¬†

  

DSX/Blog: Graphs I made which made me fall in love with data:¬†

- Domain: Uni project
    
- Domain: Pairs trading
    
- Affinda, coloured dot plot¬†
    

DSX.¬†

  

DSX: ‚ÄòJoe (Affinda)‚Äô - the most important thing if you‚Äôre in software/tech is the ability to leran new, different tech It's important to remember though, fuzzy matching will never be 100% accurate and should be used as a heuristic

  
  

DSX:¬†

  
  

can you do it in a monthly granularity, and also make the colours of the bars #4cfc24

and the kernel line #142c60

  
[Python](https://www.python.org/) is a general-purpose programming language. It was created in the late 1980s by Guido van Rossum. It is now one of the most popular languages in the world. It is routinely used by system administrators and web developers. Also, many scientists are using Python thanks to libraries such as NumPy, SciPy, pandas, and matplotlib. The ease of use of Python and its dynamic nature make it a very productive language.  
  
[IPython](https://ipython.org/) is an interactive command-line terminal for Python. It was created by Fernando Perez in 2001. IPython offers an enhanced read-eval-print loop (REPL) environment particularly well adapted to scientific computing.

  

DSX: inplace meaning - simple. Change in place, or return the new, changed DF¬†

Ge tto python. SHa,e I started so late.¬†

Writing the most beautiful script that they legit cannot do without python‚Ä¶ maybe. Everything is just na abstraction of python.¬†

  

DSX: How to specify the index at time of creation vs. change the index to a column¬†

Might offer lunch. Duke‚Äôs.¬†

Just say you can wait. Don‚Äôt be extra and get cooked.¬†

Workplace office sighs. And¬†

Vector space

  

DSX - what is serialisign.¬†

Study + Workout.¬†

  

Basic creating a dataframe and manipulating it

**


Make bold things coloured. 

***PRELUDE**
	Quantitative Data Science Intro ...................................................................................................12
==***ACT I:***== Machine Learning [[#`Machine Learning`]]
	40 ML models ..............................................................................................................................
	Data collection
	Models 
	Evaluation 
	[[#Linear Algebra]]Linear algebra and calculus .......................................................................................................
***ACT I:*** Machine Learning
	Fundamentals
	All machine learning models
	Case studies
	linear algebra
	Calculus
***ACT II:*** Prob and Stats [[# `Probability and Statistics`]]
	20 Probability Distributions
	Advanced Statistical models
	Quantitive probability
		Easy
		Medium
		Hard
***ACT III:*** Deep Learning
	Fundamentals
	All deep learning models
	Case studies
***NOCTURNE:***  [[#Databases and SQL]]
	Data structures and algorithms
	Databases and SQL
	Computer systems
	Logic
	Reading papers


**1000 technical data science and machine learning questions**

‚úª - must know
‚úª‚úª - would be nice to know
‚úª‚úª‚úª - don't need to know




The vision: 
- 'Quantitative Optimisation and MAchine lEarnin
- Machine Learning Lore
- 1429 interview questions for machine learning datascience, and quantitative finance. 



everything that scratches my brain, in a diary, handwritten 

Request Inbox: for things you'd like to be added. 

please don't make the examples unnecessarily complex. Leetcode. Is he into me. Create ze vlog
bad for me
fuck off. every single part of it works perfectly. Just get the photos and svg's in iterately


https://youtu.be/zCEYiCxrL_0?feature=shared THIS ONE >>> 


Nah easy just chapters along the LHS andyeah
Coloured text hightlighting paper style

- 

{ 1a }

Random Sample $X_1, \dots, X_n$

‚ù°

https://arxiv-sanity-lite.com

https://hastie.su.domains/ElemStatLearn/printings/ESLII_print10.pdf

https://www.deeplearningbook.org/front_matter.pdf

https://cs231n.github.io/aws-tutorial/

sci kit learn optimise 
Tom's final Optiver question + the optiver book 


**MUST READ THAT PYTHON FOR DATA ANALYSIS BOOK AND STUFF FROM KESHI SLIDES**

'read with the once and for all mentality. Tell yourself, i am going to learn this once, and then understand it forever.'
***Lots of mini quizzes justin.*** 

MINIMISE THE LOSS FUNCTION, MAXIMISE THE LIKELIHOOD FUNCTION. 


**Function maximisation... hmmm.... And explaining algebraically how maximum likelihood estimation works and the asymptotic proofs.** - DSX. ML. Moli... Run and N95

Visualise the knowledge physically attaching to your brain. w

On the heirarchy of Human - Learning. Reading is a very **weak** method. Get a 5x multiplier by not reading off the page but trying to digest the concepts themselves, and repeat o

CAPITAL E.G AND I.E

**Data vs Information**
![[1661809921482.jpeg]]

Just make the diagrams in inkscape - very cleanly tho. 
![[1_oO0KYF7Z84nePqfsJ9E0WQ.png]]


Roberts distribution. 

unnecessary wordiness is the death of communication. 

A dotted line 'cover me and repeat the answer'

The bible. I am very grateful. [[ds.x++.pdf]] edit in source. less is more. 
Use it for commentary on delayed gratification (using the marshallow example)
READ UR BOOKS. 

Make ze designs consistent with ‚òû. Change the dotpoints. 
Content > Wording. Concise. 

get some actual really good pastel highlighters for the sketches please. Just alter contrast and shit. 

For DS-X:¬†

- Tom‚Äôs mock interviews from Optiver and Citadel and Sig¬†
- Tatiana¬†
- Reddit and Glassdoor
- Leetcodes!

The simple mathematical reason ChatGPT won't change the scene: 
$$\text{your skill} \geq \text{someone else}$$
$$\implies$$
$$\text{your skill} + ChatGPT \geq \text{someone else} + ChatGPT$$

https://medium.com/data-professor/101-data-science-quotes-afad20d1e6ee#:~:text=‚Äî%20Carly%20Fiorina-,‚ÄúThe%20goal%20is%20to%20turn%20data%20into,%2C%20and%20information%20into%20insight.‚Äù&text=‚ÄúWe%20have%20to%20learn%20to,%2C%20not%20just%20our%20algorithms.‚Äù&text=‚ÄúThe%20best%20way%20to%20learn,is%20to%20do%20data%20science.‚Äù&text=‚ÄúErrors%20using%20inadequate%20data%20are,using%20no%20data%20at%20all.‚Äù

Wait this has to be like an actual **TEXTBOOK** thing. 


![[Pasted image 20231103184653.png | 200]]

make all bolded words red and highlted words rainbow. 
Not TDLR but **MORAL: **

QUESTION IDEAS: 
- data analysis
	- Observational Study vs Experiment 
	- representativeness. 
- reading comprehension test (read the sentence then answer the questions, affinda style)
- if you missed the double 'the' you need more attention detail. 
- Lost quote¬†
- What is a guard. FUCK I WISH I TRIED IN FOA
- Test python errors: you BETTER learn this shit urself
- Maximising the log-likelihood doesn't always have to involving setting the derivative = 0, just look at it and figure out what maximises it. 
- question 7, 2017 stats exam is neat. 
- Simpson Paradox; in a way you're comparing two different treatments
	- instead of 'most effective for kidney stones' should be 'most effective for small ones, most effective for large ones' or it should be a **weighted average**
	- Relationship between X and Y confounded by Z. 
- How could you use user based reinforcement learning to sublty train your model - chat GPT thumbs up thumbs down. Talk through an actual implementation. 
- What is the minimax algorithm. 
- **observed** vs **RANDOM**
- explain the statement 'more info = more power' (In a statistical sense, dummy)
	- power is the probability of correctly rejecting $H_0$ given that it is actually false. When a statistical test uses more 'information' present in the sample, it has higher power, meaning essentially that it is more likely to be reject when it **supposed to**. 
- What is BI, Data Warehousing, Star Schema, Dimensions... 
- Question 4 and 5 from week 2 stats... good. and q9 
- A question that goes through Simpson's paradox and sampling bias
- A question that goes through all types of Bias' with sick examples 
- Observational study vs Experiment w/ marshmallow experiment, and ram's nut times. 
- Function notation $\overset{the reals}{R}$
- How do you think Spotify's 'Song Radio' feature works. 
- Quick! what's seventy one times forty one? 
- Machine learning: class of blah blah for problems that cannot be explicitly programmed into a machine - i.e handwritten digits. leetcode 22 tho..  
- Problem solving
	- Counter example 
	- Simplest case - Robert
	- Root cause analysis 
	- ... 
- https://youtu.be/CFkhUajb8c8?si=fuBS8q8Cbkjkcm4p Explain the fundamental steps in creating a Chess AI. I want you to create a simple chess AI. explain the steps you would take. 
- - Using more information gives it more power given the additional assumptions are met
- Really good hypothetical question game such as 
	- 'How would company X go about (predicting/measuring/aggregating) Y'
	- E.g how do you think Spotify does the blend playlist thing 
	- How do you think Google decides which pages to show (10 blue links)
		- PageRank
	- How do you think Amazon does X 
	- How do you think 
- locking
- Keshi's shit
- ![[Pasted image 20231119192741.png]]
- Does more parameters = better model? (#deeplearning)
- What is RLHF - ChatGPT 
- The **first legendary question** (rank questions by importance)
	- "What is a statistic, in the mathematical sense": **A FUNCTION OF THE DATA**
- ALl neural net stuff; adversarial, graph neural nets, 
- What does it mean for data to be 'held ransom'
- Batch processing
- RESTORE vs RECOVER. 
- Do a roguht mental sketch for the shape of the following functions: 
	- sinh, cosh, tanh 
	- 1/x, 1/x^2, 1/x^3, ... 
	- x^2
	- log(x)
		- Is undefined at: 
		- Is negative until: 
		- Is less than one until (fracrtional) 
		- Grows____ beyond this point. 
	- e^x
- two wasy to find least squares line: linear algebra and statiscs
- What is a symbolic math library
- What is a Redundnat array of jseiofjesif disks
- WHAT IS THE 3-2-1 BACKUP PLAN. 
- What is the simplest way to build a has function which maps an integer between 0 and 100 to 5 buckets. ![[Pasted image 20231029010423.png]]
- 
- $2^5, 5!$
- ![[Pasted image 20231024073647.png | 100]] explain this
- How to use linear algebra to compare smilarity of two pictures. 

- What is a differential equation (engineering but good to know)
- ![[Pasted image 20231023141932.png]]
Certainly! Here's the information in the requested format:

| Name                          | Info                                                                                                                            |
|-------------------------------|---------------------------------------------------------------------------------------------------------------------------------|
| **UC Berkeley Gender Bias**   | At UC Berkeley's graduate admissions, women seemed less favored overall. However, by department, women often had higher rates. |
| **Kidney Stone Treatment**    | Treatment A seemed better overall. When considering stone sizes, Treatment B was more effective for both small and large stones.  |
| **Basketball Free Throws**    | Player A might have a better free throw percentage in both the first and second halves of games. But over an entire season, Player B could have a better overall percentage, especially if Player B took many more shots during games where they performed exceptionally well. |
| **Economic Trends**           | Despite rising salaries in both tech and agriculture, the overall average might decrease if more workers shift to agriculture.  |
| **Lung Cancer and Smoking**   | In some age groups, non-smokers had higher lung cancer rates. Overall, smokers had a higher risk. Age was a confounding factor. |


FORGOTTEN QUOTE  - remember the rule: no OCD else this book don't get compelte 


Teach that $\implies$ means implies, like the quant one. 
What does 'symbolic' computer mean. 


The frameworks table from the Dsci book
separate the e.g's

I need to do a mock
gradient text hightlihgt

[https://youtube.com/shorts/xyK4rBArOXs?si=n3Su7ZHMJP3Nu3Dj](https://youtube.com/shorts/xyK4rBArOXs?si=n3Su7ZHMJP3Nu3Dj) - DSX. - ChatGPT paper attention is all you need. Break it down. 
https://youtube.com/shorts/Z9jj0-aK5T0?si=R0Qzv9wsmGeAgf84


A corpus of quantitative wisdom.

--- 

The structure of this book is **very simple** (draw map)

`1. Intro`
`2. ML` 
`3. Prob&Stats` 
`4. Deep Learning` 
`5. Extras`

***PRELUDE**
	Quantitative Data Science Intro ...................................................................................................12
***ACT I:*** Machine Learning 
	40 ML models ..............................................................................................................................
	Linear algebra and calculus .......................................................................................................
	14 functions important for ML (sigmoid, tanh, log)
***ACT II:*** Prob and Stats 
	20 Probability Distributions
	All statistical tests
	Advanced Statistical models
	Combinatorics
	Quantitive probability
	Brain Teasers (sprinkled throughout)
***ACT III:*** Deep Learning
	AlphaGo
	Neural nets
	CNN's 
	Stable diffusion
***NOCTURNE:*** 
	Data structures and algorithms
	Databases and SQL
	Computer systems
	Logic
	Reading papers
	Miscellaneous
		Game theory
		Economics
		

---

[[# Prelude]] [[#Data Science]]
	[[#Intro Questions]]

Omit^ just go straight into ML, do lin alg and advanced stats after. 
[[#Act I]] [[#Machine Learning]] - supervised vs unsupervised, what is a 'lookahead'
		[[#Principles]]
			Asymptotics 
			'Stochastic'
		[[#Models]]
			Recite the steps in a KNN algorithm (out loud)
			Recommender systems 
			pytorch optimise

[[#Act II]] 
	[[#Linear Algebra and Calculus]]
		Vectors
		basic: sigmoid function, tanh, arctan, etc... all that shit. 
		basic sums and series 
		QR decomposition
		What is an eigenvector
		partial derivative
		Determinant, eigenvector, eigenvalue
		Positive semidetermite/definite matrix
		LU Decomposition and Cholesky Decomposition
	[[#Probability and Statistics]] $E(X) = E(E(X|Y))$ - advanced statistical methods and models 
		[[#Distributions]] - use that pdf. 
	[[#Data Analysis]] **NO**

[[#Act III]] [[#Deep Learning]]


	[[#Nocturne]]
		[[#Algorithms]] (since I believe everyone should know them, including Data Scientists)
			Knapsack
			A* 
			Everything from both computing subjects 
			Use the Optiver Funded website
		[[#Data Structures]] 
		[[#Numerical Methods]]
			Monte Carlo
			Finite difference method
		[[#Programming]]
			[[#Python]]
			Pandas
			Numpy
			Pytorch
			tensorflow
	[[#SQL]]
	[[#Miscellaneous]]
		Cognitive bias list 

[[#Advice for the Interview]]
[[#How to Read Papers]]

AI Resources
	[https://huggingface.co/](https://huggingface.co/)¬†  
	[https://cloud.google.com/free](https://cloud.google.com/free)  
	[https://azure.microsoft.com/en-us/free/](https://azure.microsoft.com/en-us/free/)  
	[https://aws.amazon.com/free](https://aws.amazon.com/free)
	[https://www.tensorflow.org/](https://www.tensorflow.org/)  
	[https://scikit-learn.org/stable/](https://scikit-learn.org/stable/)  
	[https://pytorch.org/](https://pytorch.org/)
	[https://medium.com/machine-learning-in-practice/my-curated-list-of-ai-and-machine-learning-resources-from-around-the-web-9a97823b8524](https://medium.com/machine-learning-in-practice/my-curated-list-of-ai-and-machine-learning-resources-from-around-the-web-9a97823b8524)
	[https://developer.nvidia.com/nemo](https://developer.nvidia.com/nemo)

**ARIMA**
- Softmax 
- Pytorch optimise


FIX THE MARGINS ON THE H6 HEADERS - CAN'T GO TOO FAR RIGHT EITHER
change astricks


This is a dense amount of information - don't stress. 

'Write a concise, plain language statement explaining this _____ to a non-statistician client '

remember: the book isn't for teaching its for answering. 

FLOW. LISTEN AND MEMROISE LIKE NO ONE ELSE. 
intro goes hard - maybe. SHAUN. 

Change the dotpoint theme. 
study stats!

- here are some interesting applications of data science - read up! 
	- From Freakonomics 
	- From 
People: 
- moz 
- robert 
- tom
- molly
- tao

consistency 
ASK UR SELF DOES IT REALLY NEED TO BE SAID 
<div class="asterix"> ‚úª I am going to use this same context for the whole section, for consistency.</div>

monologue less is more okay do another leetcode / hackerrank. 

I need to try harder if I want this book to be the holy grail like lear data science from scratch type shit. Like if u want it to blow up you have to make it good, small and large. - which means **most understandbale**

be > say

fill in the blanks

**NO COPY AND PASTING - WHEN YOU COPY AND PASTE YOU COMPLETELY BYPASS LEARNING + RISK PLAGIARISM**

LESS IS MORE 

- Kindle Highlights on the Data Science Interview Book 
- Be able to answer the basics, well - less words. 
- Naive Bayes 


1, 2.1, 2.2, 2.3) 

say I.e or **for example:**

How to explain and write maximially - try

extra: 
less unnecessary jargon for the brain to unnecessarily digest. 
don't add links to other sources - no one want sthose. Mew. 

everything on Kidnle + in comments 

**For example**
**explanation**

more code less stats
must credit robert

cleaner is better, less is more
hit up Tatiana. About the book and about ML Canva and idk... iniaitive no audacity
Leetcode > this \

Grateful for LaTeX font 

'Often transforming the variables by the `log()` function helps us see linear association between variables.' - proof that linear regression needn't be linear. 

DO NOT TRUST GPT-MATH - handwrite it. 
Causation Correaltion

Quantitative, data science, statitics. 

handwritten with character, as compressed as possible. 

What is walds test?

rudimentary aesthetics. 

Marshmallow expeirment: 
> Certainly! The "Marshmallow Experiment" was a series of studies on delayed gratification conducted in the late 1960s and early 1970s by psychologist Walter Mischel. In the experiment, young children were placed in a room with a single marshmallow and given a choice: they could eat the marshmallow immediately or wait for about 15 minutes without eating it, in which case they would be rewarded with a second marshmallow. The aim was to measure the children's ability to delay gratification. Follow-up studies found that children who were able to wait longer for the greater reward tended to have better life outcomes in areas like education and health. The experiment highlights the significance of self-control and its potential long-term implications.

Case in point. I lvoe reading this shit - very grateful. 

Make sure the book is like: Perfect. That is actually a really good example for my data science book. Any other data science related events that could be used? I.e visits to a website, fraud detection, network traffic - general things a data scientist usually deals with
#F-ocus, amen. Woww she REALLY doesn't... 

be more systeatic
Thank Tutoring 
  

Workout. I love graphical designs + the thing that made me fall in love w‚Ä¶ I have to think of solid answers to

1. Tell me about a time you‚Äôve used‚Ä¶¬†
2. Why data science
3. Tell me about a time you‚Äôve: failed,¬†

Affinda: ask about spark/hadoop. Genuinely if I just commit like 5 hours a sat/sun to learning it and do **one** good project on air

make it FOCUSED. pure DS models. Grind. and 

better astericks. Make it tracey readable 

**Clearly Explained**

don;t ever think it can't happen to you 

- what is exploratory data analysis 
'Name the feature' questions
keep it simple stupid

copy, paste, mEMORISE. we do too much copy and pasting
how to explain everything without being condesnding

'algorithm = Model (before the python section)'
'The Concorde is the most efficient animal... until you give a human a bicycle' - Steve Jobs
'3 million customers on the web... I should have 3 million store' - Amazon
**It's not about how many training iterations you do, or what training model you iuse. Ultimately. it's about how you perform in prod.** 




:')
'If you've made it this far, you deserve a treat - take this ASCII cat.'
ACT VIII) 
Next question: What is ASCII

**everything in laymens terms** - think statquests. and then. LAYMANS. 
> for technical defintiions 

- y^DISP - pretty latex style

please stop creating half complete questions. 
‚Ä†‚Ä°‚úΩ‚ú∫‚ÅÇ

need to hook em in with the models and ooh at the starst

### `NO COPY AND PASTING`

PASS IN THE INTERVIEW >>> 

**Remarks**
1. Sure, read this book, but: it needs to be in **your** üß†
2. explain selflessly - explain it in such a way that people will realise/'get' things for the first time reading this book, not ignorant, only as much information as they need. Just tell it intelligetnyl, easily, makes sense
3. This is not the place to learn these concepts - if you encounter something new, I will link to sources to learn the concept if you don't already know it. 
Sit still, mew, don't touch your hair, don't clouch, don't shake ur leg. Focus. Be Grateful. 

'all models are wrong, some are useful'
‚ÄòOne million gertclees (omg)
another one - I think it was from a statquest? maybe when I was driving to hairdressers? 

be prepared for deep dives
be prepared to be questioned about ANYTHING YOU SAY

https://towardsdatascience.com/6-ways-to-encode-features-for-machine-learning-algorithms-21593f6238b0
https://towardsdatascience.com/6-ways-to-encode-features-for-machine-learning-algorithms-21593f6238b0

Find a way to represent the follow ups 

The paradoxes in prob lecture 1
- The latter part of the probability quant  book 

exploit GPT. Midjourney for images - images are really good 
Sources + literally show these:¬†

- Jane street mock trader interivew
- Sai. 
- Kai call¬†
- Sai‚Äôs message¬†
- PDF‚Äôs
- Kindle books¬†
- YouTube
- Simplilearn articlr
- Tom's quant questions. 
- Quant book
- 42 models 
- Mock interviews 
- youtube 
- reddit and glassdoor
- 

`Hint:`
> definition
Less is more
Answer: 

less convolution, easy, most lean explanation

kyla
I need a huge favour
Can you think of any pun involving 'gradient descent' and food/recipes

reader. source mode. less words. 

This is fun. Write - on ya MacBook. Mew. Please - less words, make more sense.

no jargon no covolution

make sur eyou give lots of open ended examples such as 'what's the issue with this methodology:' and the answer will be a lookahead or something. 

- in how few dotpoints can I explain
- concise concise. 

less is more `<br>` so sexy. Cover everything so simply
lessi smore less ismore 

Could you give an intuition explanation for SS(A), SS(B) and SS(E) in two way anova? 


```
Format in # Q5) **Question goes here** Answer goes here (try to make it as clear and straightforward as possible
```
practice practice practice 
You might know your shit but remember your interviewer only means of estimating your DS-IQ is through how you communicate to them. 
Atomics Habit quote about improving (with a cool sketch)
Understanding is a beautiful thing that looks elegant, but really takes a lot of effort, during which you will feel dumb as a log
'Truly understanding something is being able to explain it to an 8 year old'
I fear not the man who has practice 1000 data science interview questions once, but 1 data science interview 1000 times. 
have more than you show, speak less than you know 
the second best time to start is now 
'Be T shaped'
less is more - as few words as possible. 
be super literal. friendly, funny. making questions. effectice. 

shorter = better 

pro tip! and speak aloud svg's (sketched), scanned, then bitmap traced - ask Moli. follow through with this make them evocaive
put them in a box 
- 'Practice speaking your answer aloud'
- 'Pro Tip'
- 'NEVER forget this'
- 'Surprise brain teaser' (sprinkled through)
- 'Try it yourself before you read the answer!'



- 'Pen and paper required' (or do it mentally)
- 'Specialised, don't really need to know, but interesting' (very deep)
- 'Tool alert!'
- 'Look say cover write check'
- 'In plain english' symbol. 
- 'Freestyle answer'


Quotes w/ little drawn figures maybe stolen from Canva: 
+One emoji
- $\mathbb{E}(X)$is the root of all heartbreak - William Shakespeare 
- Alan turing
- "Once you learn something it is yours forever" - Author
- 
- https://techvify-software.com/35-best-coding-programming-quotes/
- "Ne'er have I met a hater doing more than thou." - William Shakespeare, probably
- "It's easy to lie with statistics. it's hard to tell the truth without statistics" - AD
- Is that feature really necessary? 
- Optimisation/automation can be more hassle than
- Preparation $\implies$ confidence. 
- ### "The best way to learn is to do." ‚Äì Paul Halmos
- "Understand the problem. Businesses care about money, and solving the problem" - A.P, Canva
- "be T-shaped" - T.K, Seek
- ü™´üîã - remembertour reasons. 
- "Build me a house of 1's and 0's" - MMM
- "Have no $\mathbb{E}(\text{xpectations})$ and be **memoryless**" - J
- "Be a sponge" - T.T, Teradata 
- 'Fuck those bitches' - L.L, Teradata
- 'These are words. Computers don't like words, they like numbers.  - Alex
- "I apologise for the confusion there" - ChatGPT
- "don't let false fear be the reason you never learnt it" - me
- "There is no illusion greater than fear (of neural network architectures)." ‚Äì **Lao Tzu**
- "I am always doing that which I cannot do, in order that I may learn how to do it." ‚Äì **Pablo Picasso**
- Data > Model - Dude
- Embed your thoughts
- Attention is all you need
- ![[Pasted image 20231024074143.png]]
- "Learn to be a doer" - Obama 

- Take big steps in the right direction to achieve success (gradient ascent)
- ***Good reading is simply being a good model; extracting as much information from your sample as possible, efficiently and effectively.***
- 'The mind is a muscle and should be exerted and trained' - Moz
- All models are wrong, some are useful. 
- If I have 1 million customers I should have 1 million stores - Jeff Bezos 
- OML (one million leetcodes)


- for questions like '3. Describe a situation where you had to clean and prepare a large dataset for analysis. What steps did you take?' 'up to you!'
- moral
https://www.reddit.com/r/ObsidianMD/comments/yqyumt/line_spacing_css/
follow through. 

<div style="text-align: right;"> 
  Your right-aligned text here.
</div>


number the q's at the end. 

In TFIDF, why do we take the log of the reward in TFIDF

Study. Not gpt

  

Make a data science food recipe pun

I GET TO PICK THE STAR ASTRICKS ARHEGRHGH very grateful. Mew.¬†

Bold. Just say ‚ÄòQ‚Äô bite the bullet. Less Lismore. The triple asterisks and my brain ugh

Prelude. Nocturne. SHhhh

  

One concept and question a night - see it‚Äôs hard that took like 30 mins.¬†

Use gpt to make it more concise. More succinct and understandable

More concise, but still technical

This book covers **everything** both in terms of concepts and resources
Major contributors include: 
- 3B1B
- Simplilearn 

less words
**explantion, example**

https://grammarist.com/punctuation/asterisk-symbol-usage-examples/

this book is designed to communicate concepts as efficiently as possible (like a compressed zip). explain as efficiently as possible (fewest words). This is for accessibility as well as clarity. If you need a better explanation, copy and paste me into chatGPT with the prompt `'explain "[insert excerpt]" to me like I'm X years old'``
See all the hate explaining is bad. Be very layman terms - no ego here.¬†

Bold words .use as few words as possible and make them make the most sense - we‚Äôre going for optimal information. Focus
if you want more technical explanations, google them!

DS-X++  *advanced edition* 

make it accessible. 

See all the hate explaining is bad. Be very layman terms - no ego here.¬†

Bold words .use as few words as possible and make them make the most sense - we‚Äôre going for optimal information. Focus

Less is more

remember, **must answer these on my own** - get benefit from PRODUCING the book
this arose bc all the resources i could find ngl, the one kai sent me, bussin, but a bit dog. Can collapse them yay!
if u gpgenerate them, please READ THEM. 
- Very simple very straightforward 
- ascii 
- hand sketches, scanner w/ printer 
- try to get even justification 
-

less wordy

less is more. No advice. 

**Sources**
https://youtu.be/l_ffdarcJiQ?si=jOu1ZynNzbTtLW48
https://youtu.be/5JZsSNLXXuE?si=wCSjV5eu4WH3meXe
https://youtu.be/_7jpEFclMNY?si=ORr5PKpLNbMpZ-fI
https://youtu.be/4Z6lxfglvUU?si=CirFJivTkI6wFbqR
https://youtu.be/DqgiUo44X-k?si=OscDkwNyP0qZ2oLm
https://youtu.be/4Z6lxfglvUU?si=V8RSbaba1Yyr-LdM
https://youtu.be/PYZPmpnbUxo?si=NOdvWbsJ1YpBcs7d
https://youtu.be/wtolixa9XTg?si=HQ__cNMBQAXGPvW2
Q1.1
Q21.39


However in my experience data science interviews at non-large companies put a huge focus on machine learning/deep learning, linear algebra, statistics, core python programming (sometimes R), SQL, spark/AWS/GCP, and data visualization (tableau, matplotlib, R)

go through wilcox tests, random forests w/ sketches 



# Contents
brain teaser surprise (sprinkled through)
- Riddles 
- Logical... 

**don't add too much structure, Act I, Act II, Act III, and intermittent breaks with my quotes and some ascii art.** 
what's a smart strucutre. 
Practice your articulation OUT LOUD 

- reddit
- people
- glassdoor

this book is T-shaped (it's shallow and breadth but it also goes deep in some places - expect your interviews to go the same. They don't have enough time (big enough of a sample size) to gauge ) 

prelude: sampling, linear algebra

This book will cover: 
- every statistical model 
- every machine learning model (note that there is a blurred line between the two)
- deep learning



Statistics
	Statistics Basics
	Statistical Models
		ARIMA 
		PCA
ML
	ML basics
	ML models 

Hill climb, gradient descent, grid search 
\*\*\* prob distributions 
\*\*\*\* deep learning
data & SQL 
algorithms & data structures 
quantitative finance
less words = better understanding. 
less is more. 

Midjourney cover is wayyyyyy ahead of myself 



50 Models - what you all came here for. And have stats for each of them. traditional statistics model vs... 
etc. Be super clear about the structure. 




Okay lets pull this together to overcome the ocd and actually get this shit pushed out. 
Then continue the stats lectures. Omg the perfect metric: no. of questions added to DS-X per day that bascialyl encapuslates everything, my reading, my writing, my learning




source mode!
don't sweat the small stuff. Read Learn ROC + draw

so excited to learn all this shit and create my book... creating a book...


recommender system matrix factorisation

# Prelude

1. What is data science and how does it differ from traditional statistics?
  
2. Can you explain the data science process or lifecycle? 

3. What are the key skills a data scientist should possess?

4. Describe the differences between supervised and unsupervised learning.

5. What is the importance of data wrangling or data cleaning in the data science process?

6. What are the advantages and disadvantages of using cloud computing in data science?

7. How do you differentiate between Big Data and traditional data, and what challenges does Big Data present?

8. Can you explain what a data pipeline is and its significance in data science projects?

9. What role does domain knowledge play in data science?

10. How do version control systems like Git contribute to the data science workflow?

11. Describe the importance of ethics in data science.

12. What are APIs and how are they used in data gathering or data integration?

13. Can you explain the concept of data munging?

14. What is feature engineering and why is it important?

15. How do data science and machine learning intersect with data engineering?

16. What types of databases are commonly used in data science? Describe the pros and cons of each.

17. Explain the concept of data governance and its relevance in data science.

18. What is the CAP theorem and how does it relate to data science?

19. Can you describe the differences between batch processing and stream processing?

20. What are common challenges you've faced in previous data science projects and how did you overcome them?

21. Hookes Laws



Sai said start with: then

# Data Analysis 

1. What is exploratory data analysis (EDA) and why is it important?
  
2. How do you handle missing data in a dataset?

3. Describe a situation where you had to clean and prepare a large dataset for analysis. What steps did you take?

4. What are some common techniques for outlier detection?

5. Explain the differences between univariate, bivariate, and multivariate analysis.

6. Describe the types of joins in SQL and give examples of when you might use each.

7. How do you approach time series analysis? Can you explain techniques like ARIMA and moving averages?

8. What are pivot tables and how would you use them for data analysis?

9. Explain the concept of data normalization and why it might be important in data analysis.

10. How would you design and conduct an A/B test?

11. Describe some data visualization techniques you have used and explain why they were effective for your analysis.

12. How would you validate the results of your data analysis?

13. What is the difference between correlation and causation? Provide an example.

14. How do you choose which variables to include in your analysis?

15. Can you explain what Principal Component Analysis (PCA) is and when it might be useful?

16. Describe the significance of p-values and confidence intervals in hypothesis testing.

17. What are some common distance metrics used in clustering? Give examples.

18. How do you perform feature selection and why is it important?

19. Explain how you would analyze unstructured data, such as text or images.

20. What are some limitations of using aggregate functions like mean, median, and mode?

# Linear Algebra

1. What is a vector space? Can you provide some examples?
  
2. Explain the concept of linear independence and its importance.

3. How do you calculate the eigenvalues and eigenvectors of a matrix?

4. What is the rank of a matrix and why is it important?

5. Can you explain the difference between the dot product and the cross product?

6. What is the significance of the determinant of a matrix?

7. How are matrixes used in recommendor systems

8. Describe the various types of matrices such as identity, diagonal, orthogonal, and symmetric matrices.

9. What are the properties of matrix addition and multiplication?

10. Explain the Gram-Schmidt process and its applications.

11. How can you solve a system of linear equations using matrices?

12. What is singular value decomposition (SVD) and what are its applications?

13. Describe how linear transformations can be represented with matrices.

14. What is the difference between a row space and a column space in a matrix?

15. Can you explain the concept of a basis in a vector space?

16. How do you find the inverse of a matrix, and when is a matrix invertible?

17. Describe what it means for vectors to be orthogonal and orthonormal.

18. What is a tensor and how does it generalize vectors and matrices?

19. How do you compute the projection of one vector onto another?

20. Explain the LU decomposition of a matrix.

21. What are some applications of linear algebra in machine learning and data science?

Absolutely, here's a revised list of Linear Algebra questions specifically tailored to applications in data science and machine learning:

1. How is the concept of vector space relevant in Natural Language Processing (NLP) or text mining?
  
2. Explain how eigenvalues and eigenvectors are used in Principal Component Analysis (PCA).

3. How can singular value decomposition (SVD) be used for dimensionality reduction or latent semantic indexing?

4. In machine learning algorithms like linear regression or support vector machines, what role does the dot product play?

5. Why is the concept of matrix rank important when dealing with datasets in machine learning?

6. What is the significance of the determinant in machine learning algorithms that involve matrix inversion?

7. How are diagonal matrices used in algorithms like diagonal discriminant analysis?

8. Can you explain the importance of orthogonality in features or data points when performing data analysis?

9. Describe how matrix factorization techniques like Non-negative Matrix Factorization (NMF) are used in recommendation systems.

10. How are systems of linear equations solved in the context of least squares for linear regression?

11. How is the Gram-Schmidt process used in QR decomposition for solving linear least squares problems?

12. Explain the role of linear transformations in data augmentation techniques.

13. How are tensors used in deep learning frameworks like TensorFlow or PyTorch?

14. What is the role of the eigen-decomposition of the covariance matrix in machine learning?

15. How is the concept of "basis" used in sparse coding or compressed sensing?

16. What are some challenges you might encounter when computing the inverse of a matrix in high-dimensional data?

17. In what ways are linear algebra operations optimized for large datasets in machine learning libraries?

18. Describe the concept of a projection matrix and its application in feature selection.

19. How are linear algebra techniques like LU decomposition or Cholesky decomposition used in machine learning algorithms?

20. What are some machine learning algorithms that heavily rely on linear algebra, and how is it applied in those algorithms?

These questions are designed to evaluate the understanding of linear algebra as it directly applies to tasks and challenges in data science and machine learning.

---

ML functions

Certainly! Here's a list of functions that are commonly used and important in the field of machine learning:

1. **Linear Function:** 
   - Equation: \(f(x) = mx + b\)
   - Used in linear regression models and as the simplest kind of activation function.

2. **Sigmoid (Logistic) Function:**
   - Equation: \(f(x) = \frac{1}{1 + e^{-x}}\)
   - Used in binary classification problems and as an activation function in neural networks.

3. **Hyperbolic Tangent (tanh) Function:**
   - Equation: \(f(x) = \tanh(x)\)
   - An activation function used in neural networks, it outputs values between -1 and 1.

4. **Rectified Linear Unit (ReLU) Function:**
   - Equation: \(f(x) = \max(0, x)\)
   - A popular activation function in deep learning models.

5. **Leaky Rectified Linear Unit (Leaky ReLU) Function:**
   - Equation: \(f(x) = x\) if \(x > 0\) else \(f(x) = \alpha x\) where \(0 < \alpha < 1\)
   - A variation of ReLU to allow small negative values.

6. **Softmax Function:**
   - Used in multi-class classification problems to convert raw scores into probabilities for each class.

7. **Exponential Linear Unit (ELU) Function:**
   - A variation of ReLU that allows negative values and smoothens the curve for negative inputs.

8. **Logarithm Function:**
   - Equation: \(f(x) = \log_b(x)\) where \(b\) is the base.
   - Used in algorithms like logistic regression and in loss functions like log loss.

9. **Step Function:**
   - Outputs 0 for all inputs less than a threshold and 1 for all inputs greater than or equal to the threshold.
   - Used in models like the perceptron.

10. **Swish Function:**
   - Equation: \(f(x) = x \times \sigma(\beta x)\) where \(\sigma\) is the sigmoid function.
   - A newer activation function that has shown promise in deep learning.

11. **Mish Function:**
   - Equation: \(f(x) = x \times \tanh(\ln(1 + e^x))\)
   - Another activation function that has shown to perform well in some deep learning tasks.

12. **Identity Function:**
   - Equation: \(f(x) = x\)
   - Used in output layers for regression problems.

13. **Softplus Function:**
   - Equation: \(f(x) = \ln(1 + e^x)\)
   - A smooth approximation to the ReLU function.

14. **Radial Basis Function (RBF):**
   - Often used in RBF networks and support vector machines.

15. **Loss Functions:**
   - **Mean Squared Error (MSE):** Used in regression tasks.
   - **Cross-Entropy Loss (Log Loss):** Used in classification tasks.
   - **Hinge Loss:** Used in SVMs for classification.
   - **Huber Loss:** Combines properties of MSE and MAE, and is less sensitive to outliers than MSE.






---



Inspired by: 
![[61YGoUsyVWL._AC_UL210_SR210,210_.jpg]]


honestly, I needed them to be harsher on me. But, I don't have a time machine so. 1,.5505 years
2 years down the drain. Never Forget. 
depression
after the worst -> the best (moli) -> then yeah 
trumpets played as I cleared my dish and wiped the table - scary

Is every business ready for data science
KNOW THE COMPANY YOU'RE APPLYING FRO (JOMA TECH)

![[Pasted image 20231010132343.png]]

# This: 

---

**Interviewer**: Good morning! Before we dive deep, can you let me know if you're familiar with both SQL and NoSQL databases?

**Interviewee**: Good morning! Yes, I have experience with both SQL and NoSQL databases.

**Interviewer**: Great! Can you briefly describe the primary differences between the two?

**Interviewee**: Absolutely. SQL databases are relational databases that store data in a structured format using rows and columns, while NoSQL databases are non-relational and can manage unstructured or semi-structured data. SQL databases have a fixed schema, whereas NoSQL databases are typically schema-less, allowing for more flexibility in data entry. SQL databases generally scale vertically, while NoSQL databases are designed for horizontal scaling.

**Interviewer**: Interesting. Can you give an example of when you might choose a NoSQL database over an SQL database?

**Interviewee**: Certainly. If I were building a content management system where the data structures needed to be flexible and could change based on user needs or if I was dealing with a system that required massive amounts of data and quick scalability, I'd lean towards NoSQL. A good example might be a social media platform where user-generated content doesn't conform to a fixed schema and the platform needs to scale horizontally with growing user base.

**Interviewer**: Makes sense. How about ACID and CAP? Can you explain their relevance to these databases?

**Interviewee**: Sure! SQL databases typically adhere to the ACID properties, which stands for Atomicity, Consistency, Isolation, and Durability. This ensures high data integrity and consistency. NoSQL databases, on the other hand, are often guided by the CAP theorem which emphasizes Consistency, Availability, and Partition tolerance. Depending on the specific NoSQL database, you might have to make trade-offs between consistency and availability.

**Interviewer**: Very well put. Lastly, can you name a few databases from each category?

**Interviewee**: Certainly! For SQL, examples include MySQL, PostgreSQL, and Oracle Database. For NoSQL, there are MongoDB (document-based), Redis (key-value store), Cassandra (column-oriented), and Neo4j (graph-based).

**Interviewer**: Fantastic! Thank you for the detailed explanations. Let's move on to the next topic.

---

**Important Information for Preparation**:

1. **Deep ML Understanding**: It's not crucial to have an in-depth understanding of machine learning for internship roles. 
   
2. **Interview Structure**:
   - LeetCode tests.
   - Mathematics and statistics questions.
   - Coding in Python.
   - Presentation of a past data science project.
   - Technical interview related to business problems, such as churn modeling.

3. **Key Skills and Tools**:
   - SciPy, TensorFlow, and Spark.
   - Ability to formulate and solve business problems using data.
   - Ability to devise modeling strategies for predicting customer behavior.
   - Data preparation and aggregation.

4. **Coding Test**: Unlike other coding tests, you might not be watched as you code during an ML interview.

5. **Internship Experience**: Being assertive about the kind of projects you want to work on can be beneficial.

**Practice Questions and Answers**:


tecnical questions
https://huggingface.co


Tom's interview questions

MLE vs Data Sciece 

what is a coronated attack 

we learn on average 50 things wper day

how can I:
change the font of my theme in obsidian
add css that allows me to add a full 'title page' when I press export
change the margins (left right on page)
adjust line spacing

**Covers:** 
- All models
	- kNN 
	- SVM 
	- linear regression
	- multiple regression
	- ARIMA 
	- ANOVA 
- All probability distributions 
	- 
- All algorithms
	- 
- All data structures 
	- Heap
	- List 
	- stack 
	- queue 
	- linked list 

  

- 1(I must be better make my questions so like nuanced and from the greatest sources and something else. ) + better + PH

- Legit gold mine all the best interview questions like be on that relentlessly get the hard niche high quality redddit ones shhh
- THE END!!!!!
- Scree plot

- Poor dan and I
- If you da master gotta live up to it; the communication coach mf. Yeah you gotta‚Ä¶. Be accountable¬†
- Covariance matrix <- wish I paid attention smh or was smarter. Simulate some mad shit
- [https://youtu.be/Aut32pR5PQA?si=QGkjd_PvrnhYUXJ5](https://youtu.be/Aut32pR5PQA?si=QGkjd_PvrnhYUXJ5) I love love love the idea that you can empirically find the ‚Äòbest‚Äô version of something - a piano player, an image, a car driver, by merely exploiting computation and learning algorithms. You don‚Äôt need to understand why. [https://youtu.be/L_4BPjLBF4E?si=QeFQbuKJMsLVzBLI](https://youtu.be/L_4BPjLBF4E?si=QeFQbuKJMsLVzBLI) I think it‚Äôs a good metaphor - Practice makes us better
- No reaction to seek HQ. And. I tried to warn her. And.
- **Must practice speed for eng math.**¬†
- **No. - bex! Adn**
- Jealous of‚Ä¶ well yeah. That tells u enough
- Katrina legit like X years older and still makes coffee like that. No Ego. Bless - and like yeah ezhi katrina veep idek.¬†
- It‚Äôs common. Have everything and still want more‚Ä¶ And.¬†
- Unethical way to get rich‚Ä¶ - getHerBack
- Program  
    

Statquest! Stop forgetting about necessity: find all Q‚Äôs and memorise Screengraohs and idk


---

# Brain teaser Questions

###### Q1) What is 18% of 150?

$27$

(**Hint**: it's the same as 150% of 18)

**Proof**
$$\frac{x\cdot y}{100} = \frac{y\cdot x}{100}$$

<br>

---

###### 

Whats next in the pattern (hackerrank)

$$1, 3, 5, 7, [?]$$

`1, 3, 5, 7, [?]`

use a siq canva element for the cover
imagine sending to moz,... imagine 


###### Quick! Find the next 2 numbers in the sequence (your life depends on it)

1, 5, 6, 11, 17, 28, 

-, 4, 1, 5, 6, 11, 

45, 



---

The relationship between the gamma distribution and the sum of independent exponentials is a classic example of how one distribution arises from the combination of others. Here are a few other distributions with similar relationships:

1. **Normal Distribution**:
    - The sum of a large number of independent and identically distributed (i.i.d.) random variables (by the Central Limit Theorem) tends to a normal distribution, regardless of the original distribution of the variables, provided they have finite means and variances.
  
2. **Chi-Squared Distribution**:
    - If \(Z_1, Z_2, \ldots, Z_k\) are independent standard normal random variables (mean 0, variance 1), then the sum of their squares, \(Q = Z_1^2 + Z_2^2 + \ldots + Z_k^2\), is distributed according to the chi-squared distribution with \(k\) degrees of freedom. This is a special case of the gamma distribution.

3. **t-Distribution**:
    - If \(Z\) is a standard normal random variable and \(V\) is an independent chi-squared random variable with \(k\) degrees of freedom, then the random variable \(T = \frac{Z}{\sqrt{V/k}}\) has a t-distribution with \(k\) degrees of freedom.

4. **F-Distribution**:
    - If \(V_1\) has a chi-squared distribution with \(d_1\) degrees of freedom and \(V_2\) has a chi-squared distribution with \(d_2\) degrees of freedom, and \(V_1\) and \(V_2\) are independent, then the ratio \(F = \frac{V_1/d_1}{V_2/d_2}\) has an F-distribution with \(d_1\) and \(d_2\) degrees of freedom.

5. **Beta Distribution**:
    - The beta distribution can be related to the order statistics of the uniform distribution. If \(U_1\) and \(U_2\) are independent random variables that are uniformly distributed between 0 and 1, then the random variable \(X = \frac{U_1}{U_1 + U_2}\) has a beta distribution.

6. **Poisson Distribution**:
    - The sum of independent Poisson random variables with parameters \( \lambda_1, \lambda_2, \ldots, \lambda_k \) is another Poisson random variable with parameter \( \lambda_1 + \lambda_2 + \ldots + \lambda_k \).

7. **Exponential Distribution**:
    - The minimum of several independent exponential random variables (each with possibly different rates) is also exponentially distributed, but with a rate that is the sum of the individual rates.

These relationships are crucial in statistical theory and practice because they allow statisticians and researchers to understand the behavior of combined random processes and to derive properties of new distributions from properties of familiar ones.



# DB: Should know all of these. 
There are several other data models apart from the relational data model. Each data model represents data in a specific way and is suited to different types of applications and use cases. Here are some other data models:

1. **Hierarchical Data Model:** This model organizes data into a tree-like structure with a single root, where each record has a parent and zero or more children. It was popular in early database systems like IBM's IMS.

2. **Network Data Model:** Similar to the hierarchical model, but it allows for more flexible relationships. Records can have multiple parents, forming a network of relationships. The CODASYL database model is an example of this.

3. **Entity-Relationship Model (ER Model):** This model represents data as entities, attributes, and the relationships between entities. It's widely used in database design to create a visual representation of the data structure.

4. **Object-Oriented Data Model:** This model extends the concepts of object-oriented programming to databases. It treats data as objects with attributes and methods and supports inheritance and encapsulation.

5. **Object-Relational Data Model (ORDBMS):** This model combines elements of both relational and object-oriented databases. It adds support for complex data types and methods while retaining the tabular structure of relational databases.

6. **Document Data Model:** Document databases, like MongoDB, use this model. Data is stored in flexible, semi-structured documents (e.g., JSON or XML) instead of tables. It's suitable for applications with varying or evolving data structures.

7. **Key-Value Data Model:** In this model, data is stored as key-value pairs. It's highly efficient for simple read and write operations but less suitable for complex queries.

8. **Columnar Data Model:** Columnar databases store data in columns rather than rows, which can be more efficient for analytical queries. Examples include Apache Cassandra and Google Bigtable.

9. **Graph Data Model:** Graph databases (e.g., Neo4j) use this model to represent data as nodes and edges. It's ideal for data with complex relationships, such as social networks and recommendation systems.

10. **Time-Series Data Model:** This model is designed for handling data that is generated and collected over time. Time-series databases (e.g., InfluxDB) are optimized for storing and querying time-stamped data.

11. **Spatial Data Model:** Spatial databases are used to store and query geographic and geometric data. They support spatial data types and operations for applications like GIS (Geographic Information Systems).

12. **Multidimensional Data Model:** Used in data warehousing and OLAP (Online Analytical Processing) systems, this model organizes data into multi-dimensional cubes to facilitate complex analytical queries.

13. **Semistructured Data Model:** This model accommodates data that doesn't fit neatly into traditional structured models. Examples include XML databases and JSON databases.

14. **Knowledge Graph Data Model:** This model represents data as a graph of interconnected concepts, entities, and relationships. It's used for building knowledge graphs and semantic web applications.

These are some of the main data models, each with its own strengths and weaknesses. The choice of data model depends on the specific requirements and characteristics of the data and the application being developed.