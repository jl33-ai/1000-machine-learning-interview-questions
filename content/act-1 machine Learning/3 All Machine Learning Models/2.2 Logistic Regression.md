> [!quote] Logistic regression is linear regression's curvier cousin - **Anonymous**

---

##### What is logistic regression? 

> [!check] Logistic regression
> - Logistic regression is used for [[1.2 Easy Questions#What are the different types of classification problems in machine learning?|binary classification]] problems. However, it is even more powerful, as it is actually able to predict the probability that a given observation belongs to a particular category.
- It works by fitting an [[S-shaped curve]] to the data using [[maximum likelihood estimation]].
- (diagram)

<br>

###### ↳ What can it be used for? 

Logistic regression is used in fields like: 
- Medicine
- Marketing
- Sales
- Economics
- Social sciences

For tasks such as: 
- Disease diagnosis
- Predicting customer churn

***Essentially, anything where knowing the likelihood of an event happing would be helpful.*** 

<br>

---

##### Name the advantages and limitations of logistic regression.

<br> 

---

##### As with linear regression, is logistic regression considered statistics or machine learning?

There is a lot of intersection between statistics and machine learning, so it is difficult to say. Even though linear/logistic come from pure, traditional statistics, they are still considered machine learning because they **use data to make predictions**. 

From a pure statistics perspective, the core of logistic regression is the** logistic model**, a way to model the relationship between some [[random variables]]. 

> [!check] The logistic model
> - Also known as the logit model
> - A statistical model that models the [[log-odds]] of an event occurring, as a linear combination of one or more [[explanatory variables]].  

Thus, logistic **regression** is the process of estimating the parameters of this logistic model (the coefficients in the linear combination). With large datasets, this may require help from computers. 

<br>

###### ↳ How do machine learning techniques improve upon traditional logistic regression? 

**Machine learning** focused on leveraging large datasets and computational power to optimize the model's ability to make classifications and predictions. It can employ data-driven techniques like cross-validation and regularization to enhance predictive performance, which cannot be done with pen and paper. 

<br>

---

##### What are the inputs and outputs of a logistic regression model (in machine learning)? 

In binary logistic regression, there is a single binary dependent variable, while the independent variables can either be binary or continuous. 

<br>

---




##### The Math

Logistic regression is a statistical method used for binary classification, where the outcome is categorized into two possible classes. It's widely used in various fields like medicine, economics, and social sciences for tasks like disease diagnosis, predicting customer churn, or evaluating the likelihood of an event happening.

### Key Concepts of Logistic Regression:

1. **Binary Outcome**: The target variable \(Y\) has only two possible outcomes, often represented as 0 and 1.

2. **Odds Ratio**: It is the ratio of the probability of an event occurring to the probability of it not occurring. If \(p\) is the probability of the event, the odds ratio is \( \frac{p}{1-p} \).

3. **Logit Function**: This is the core of logistic regression. The logit function is the logarithm of the odds ratio, i.e., \( \log\left(\frac{p}{1-p}\right) \). It maps probability values from 0 to 1 into real numbers ranging from negative infinity to positive infinity.

4. **Sigmoid or Logistic Function**: The inverse of the logit function, this function maps any real-valued number into a probability value between 0 and 1. It's given by the formula: 
   \[ \sigma(x) = \frac{1}{1+e^{-x}} \]
   where \(x\) is the input to the function, \(e\) is the base of the natural logarithm, and \(\sigma(x)\) is the output probability.

### Function in Logistic Regression:

The logistic regression model predicts the probability that a given input belongs to a particular category. The function involved is as follows:

1. **Linear Combination of Inputs**: First, a linear combination of the input features (\(X\)) is created, similar to linear regression. This is given by:
   \[ z = \beta_0 + \beta_1X_1 + \beta_2X_2 + \cdots + \beta_nX_n \]
   where \( \beta_0, \beta_1, \ldots, \beta_n \) are the parameters of the model, and \(X_1, X_2, \ldots, X_n\) are the input features.

2. **Applying Logistic Function**: The linear combination \(z\) is then passed through the logistic function:
   \[ P(Y=1|X) = \frac{1}{1+e^{-z}} \]
   This gives the probability of the instance belonging to class 1 (Y=1).

### Estimation and Interpretation:

- The parameters \( \beta \) are estimated using a method called Maximum Likelihood Estimation (MLE).
- The coefficients \( \beta \) can be interpreted in terms of odds ratios. A positive coefficient increases the odds of the outcome being 1, and a negative coefficient decreases it.

### Advantages and Limitations:

- **Advantages**: Logistic regression is simple, interpretable, and provides probabilities for outcomes.
- **Limitations**: Assumes a linear relationship between the log-odds and the predictors; it may not perform well with non-linear data or with a high number of categorical features.

In summary, logistic regression is a powerful and straightforward way to model binary outcomes by transforming a linear combination of inputs into a probability using the logistic function.