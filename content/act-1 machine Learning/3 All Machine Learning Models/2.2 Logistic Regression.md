> [!quote] Logistic regression is linear regression's curvier cousin - **Anonymous**

---

##### Can you explain what logistic regression is and how it differs from linear regression?

> [!check] Logistic regression
> - Logistic regression is used for [[1.2 Easy Questions#What are the different types of classification problems in machine learning?|binary classification]] problems. 
> - It is used to predict the probability that a given datapoint belongs to one of two classes. 
> - It works by fitting an [[S-shaped curve]] to the data using [[maximum likelihood estimation]].
> - (diagram)

**Linear vs Logistic Regression**

**Inputs**: Both types are able to take one or more input variables, and they can be either continuous or categorical. 

**Outputs**: Linear regression outputs a continuous prediction value (e.g $33.29kg$) while logistic regression outputs a probability between $[0, 1]$ corresponding to the likelihood of the datapoint belonging to one of two classes. 

**Line**: Linear regression fits a straight line to the data, while logistic regression fits an S-shaped curve. 

**Fitting method**: Linear regression uses least squares, whilst logistic regression uses maximum likelihood. 

<br>

###### ↳ What can it be used for? 

[[2.2 Logistic Regression#Can you explain what logistic regression is and how it differs from linear regression?|Logistic regression]] can be used for the usual [[act-1 machine Learning/1 Fundamentals/1.1-intro-questions#What is classification? Can you name some examples?|classification tasks]] such as: 

**1. Determining the probability of heart attacks**: Medical practitioners could determine the relationship between variables such as the weight, height, exercise levels, of an individual and use it to predict whether the person will suffer from a heart attack.

**2. Possibility of enrolling into a university**: Application aggregators can determine the probability of a student getting accepted to a particular university or a degree course in a college by studying the relationship between the estimator variables, such as ATAR, SAT, GMAT scores.

**3. Identifying spam emails**: Email inboxes are filtered to determine if the email communication is spam by understanding the predictor variables and applying a logistic regression algorithm to check its authenticity. 


***Logistic regression is particularly useful if the classification is binary (yes or no), and if knowing the likelihood as well as the classification is useful.*** 

<br>

---

###### What is the S-shaped curve? 

**The equation of the curve is:**

$$
y = \frac{e^{a + b X}}{1+e^{a+b X}}
$$

A few things to note: 
1. The function's range is between $(0, 1)$, corresponding to [[act-2 prob and stats/1 Fundamental Probability/1.1 Easy Questions#What are the three axioms of probability?|probability]].
2. $a, b$ are the **parameters** which control the shape and position of the curve. Note that this equation is only for one input variable; if there were two input variables then we would have $a, b, c$
3. $e$ is just [[Euler's constant]].

If you're interested in the math, go down to [[2.2 Logistic Regression#Explain the math behind logistic regression. Where does this S-shaped curve come from and how is it actually fit to the data?|here]], but in short, this is the inverse of a function which transforms **probabilities** into **log-odds**. Therefore, this function does the opposite, squishing log-odds into probabilities. 

<br>

###### ↳ How is this S-shaped curve fit to the data? 

Otherwise, just know that the final S-shaped curve is chosen such that this particular curve maximizes the likelihood of the 'training' datapoints. 

<br>

###### What is this S-shaped curve, and why is it used? 




<br>










---

##### Name the advantages and limitations of logistic regression.

- **Advantages**
	- Very lightweight and easy to implement
	- Highly interpretable, since it outputs the probability of being in a certain class. 
- **Limitations**
	- Assumes a linear relationship between the log-odds and the predictors
	- It may not perform well with non-linear data or with a high number of categorical input features.

<br> 

---

##### What are the assumptions made by logistic regression?

Answer placeholder

<br>

---

##### How do you interpret the coefficients in a logistic regression model?

Answer placeholder

<br>

---

##### How do you evaluate the performance of a logistic regression model?

Answer placeholder

<br>

---

##### Can you discuss different methods to select significant variables in a logistic regression model?

Answer placeholder

<br>

---

##### What are the common metrics used to assess a logistic regression model's accuracy?

Answer placeholder

<br>

---

##### Describe a real-world problem where you have applied logistic regression. What were the challenges and how did you address them?

Answer placeholder

<br>

---

##### How do you handle imbalanced classes in logistic regression?

See the original question and answer [[1.3 Hard Questions#How do you mitigate the problem of class imbalance, and why is it important?|here]]. 

Methods specific to **logistic regression**: 
- 

<br>

---

##### Can you discuss how to implement logistic regression for multi-class classification?

Answer placeholder

<br>

---

##### What is regularization in logistic regression, and why is it important? Can you compare L1 and L2 regularization?

Answer placeholder

<br>

---

##### How does logistic regression handle non-linear relationships in the data?

Answer placeholder

<br>

---

##### Can you explain the concept of odds ratio in the context of logistic regression?

Answer placeholder

<br>

---

##### How would you optimize the performance of a logistic regression model?

Answer placeholder

<br>

---

##### Discuss a scenario where logistic regression might not be the best model choice. What alternatives would you consider?

Answer placeholder

<br>

---

##### Explain how you would deploy a logistic regression model in a production environment.

Answer placeholder

<br>

---

##### Explain the math behind logistic regression. Where does this S-shaped curve come from and how is it actually fit to the data? 

We will again break it down into a sequence of logical steps. 

###### Step 1

Like linear regression, we want to fit a curve. We need to get to a probability, which we know lies between 0 and 1. So if we work backwards. But to fit a line, we need the 

We can transform 


Logistic regression is a statistical method used for binary classification, where the outcome is categorized into two possible classes. It's widely used in various fields like medicine, economics, and social sciences for tasks like disease diagnosis, predicting customer churn, or evaluating the likelihood of an event happening.

### Key Concepts of Logistic Regression:

1. **Binary Outcome**: The target variable \(Y\) has only two possible outcomes, often represented as 0 and 1.

2. **Odds Ratio**: It is the ratio of the probability of an event occurring to the probability of it not occurring. If \(p\) is the probability of the event, the odds ratio is \( \frac{p}{1-p} \).

3. **Logit Function**: This is the core of logistic regression. The logit function is the logarithm of the odds ratio, i.e., \( \log\left(\frac{p}{1-p}\right) \). It maps probability values from 0 to 1 into real numbers ranging from negative infinity to positive infinity.

4. **Sigmoid or Logistic Function**: The inverse of the logit function, this function maps any real-valued number into a probability value between 0 and 1. It's given by the formula: 
   \[ \sigma(x) = \frac{1}{1+e^{-x}} \]
   where \(x\) is the input to the function, \(e\) is the base of the natural logarithm, and \(\sigma(x)\) is the output probability.

### Function in Logistic Regression:

The logistic regression model predicts the probability that a given input belongs to a particular category. The function involved is as follows:

1. **Linear Combination of Inputs**: First, a linear combination of the input features (\(X\)) is created, similar to linear regression. This is given by:
   $z = \beta_0 + \beta_1X_1 + \beta_2X_2 + \cdots + \beta_nX_n$
   where \( \beta_0, \beta_1, \ldots, \beta_n \) are the parameters of the model, and \(X_1, X_2, \ldots, X_n\) are the input features.

2. **Applying Logistic Function**: The linear combination \(z\) is then passed through the logistic function:
   \[ P(Y=1|X) = \frac{1}{1+e^{-z}} \]
   This gives the probability of the instance belonging to class 1 (Y=1).

### Estimation and Interpretation:

- The parameters \( \beta \) are estimated using a method called Maximum Likelihood Estimation (MLE).
- The coefficients \( \beta \) can be interpreted in terms of odds ratios. A positive coefficient increases the odds of the outcome being 1, and a negative coefficient decreases it.

### Advantages and Limitations:


In summary, logistic regression is a powerful and straightforward way to model binary outcomes by transforming a linear combination of inputs into a probability using the logistic function.




---

##### As with linear regression, is logistic regression considered statistics or machine learning?

There is a lot of intersection between statistics and machine learning, so it is difficult to say. Even though linear/logistic come from pure, traditional statistics, they are still considered machine learning because they **use data to make predictions**. 

From a pure statistics perspective, the core of logistic regression is the** logistic model**, a way to model the relationship between some [[random variables]]. 

> [!check] The logistic model
> - Also known as the logit model
> - A statistical model that models the [[log-odds]] of an event occurring, as a linear combination of one or more [[explanatory variables]].  

Thus, logistic **regression** is the process of estimating the parameters of this logistic model (the coefficients in the linear combination). With large datasets, this may require help from computers. 

<br>

###### ↳ How do machine learning techniques improve upon traditional logistic regression? 

**Machine learning** focused on leveraging large datasets and computational power to optimize the model's ability to make classifications and predictions. It can employ data-driven techniques like cross-validation and regularization to enhance predictive performance, which cannot be done with pen and paper. 

<br>