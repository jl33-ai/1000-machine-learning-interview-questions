# Application

Leetcodes: `XXX`
	Pandas
	SQL
	Neetcode
HackerRank: `XX`
	All
Kaggle: `X`
	All

Trying to learn machine learning? Let me put you on some **good stuff**



1. This book - listen to some [classical music]()
2. Long educational videos to fall asleep to [here]()
3. HackerNews
4. Andrej Karthov 
5. StatQuest
6. AndrewNg Courses
7. Hastie, Tibshirani
8. 3B1B

First, read fucking Hastie, Tibshirani, and whoever. Chapters 1-4 and 7-8. If you don't understand it, keep reading it until you do.

You can read the rest of the book if you want. You probably should, but I'll assume you know all of it.

Take Andrew Ng's Coursera. Do all the exercises in python and R. Make sure you get the same answers with all of them.

Now forget all of that and read the deep learning book. Put tensorflow and pytorch on a Linux box and run examples until you get it. Do stuff with CNNs and RNNs and just feed forward NNs.

Once you do all of that, go on arXiv and read the most recent useful papers. The literature changes every few months, so keep up.

There. Now you can probably be hired most places. If you need resume filler, so some Kaggle competitions. If you have debugging questions, use StackOverflow. If you have math questions, read more. If you have life questions, I have no idea.

---

This is the right answer. It was somewhat useful five years ago, but nowadays, the answer has to at least include software experience (at the very least some knowledge of clean code, vectorization and parallelization), application of pretrained models, basic MLOps like CI/CD, deployment, data pipeline tools, cloud tools, Agile if we're being honest, usage of at least one boosting library, and even then the MLE roles themselves need way more experience in implementation and basic software engineering practices.

It's so much more mature now and thus more complex. It'd be fairly easy to keep the post up to date, but the list would become a bit pointless since the information would be a tidal wave.

---

Yes to hastie and tibshirani - introduction to stat learning is probably worth it but elements is more of a reference book. This is like a good intro to basic ml methods in R from a statistical perspective, most of which are available in the scikit learn library.

Yes to Andrew Ngs course unless you can get your hands on something that will give you a more theoretical foundation of ML. There aren’t many textbooks that are succinct in this regard. You want to have an understanding of gradient descent and convex optimisation generally, surrogate loss functions, PAC learning, regularisation etc. These are the basics that will let you understand many themes in ML.

A good theoretical extension would be probabilistic machine learning by Kevin Murphy.

Do the FastAI course to get to grips with practical approaches to deep learning, and yea read the DL book at some point.

Yeah start doing some kaggle if you don’t have uni/work related to ML. Just looking at other peoples code and trying to understand it will help loads.

But honestly order is not that important. If you have enough math then do any of the above in whatever order you like, they mostly cover the similar content from different perspectives.

Edit: this also completely depends on your goals, if you want to work as an ML engineer at a big company and move towards research or something then all of the above are probably necessary. If you have no interest in research then focus on understanding all the basic methods and being able to apply them.


https://youtu.be/VMj-3S1tku0?si=l3kXAhaTof-eHM06 5:00

https://youtu.be/aircAruvnKk?si=OJXBb_P056pVYJCw