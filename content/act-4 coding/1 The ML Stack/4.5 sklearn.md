Now you're ready for `sklearn`

Like leetcodes but for ML - I should make that. There's minimum like predictive performance requirements. 

---

https://scikit-learn.org/stable/


### What is `scikit-learn`?

> [!check] `scikit-learn`
> - Abbreviated to `sklearn`
> - A Python library (package) containing lots of useful machine learning functionality. 
> - `sklearn` gives you the ability to use any of the machine learning models covered in [[2.0 Preface|this section]], able to fit to the data in a single line of code. 
> 
> **More fun facts**: 
> - It user-friendly and efficient
> - Built on [[4.5 numpy|numpy]], [[4.5 scipy|scipy]], and [[4.4 matplotlib|matplotlib]]
> - Open source, commerically usable under the [[2.4 Git#Are you familiar with various licenses?|BSD License]]  


<br>

---

##### Can you explain the structure of the `sklearn` package?

Make sure you understand how Python libraries are structured by answering [[2.3 Pythonese (hard)#Can you explain the internal structure of a Python package? What is the difference between a package, module, and class? Use the example `from sklearn.ensemble import RandomForestClassifier` to assist your explanation|this question]]. 

```text
scikit-learn (sklearn)
│
├── base
├── cluster
│   ├── AffinityPropagation
│   ├── AgglomerativeClustering
│   ├── Birch
│   ├── DBSCAN
│   ├── KMeans
│   ├── MiniBatchKMeans
│   ├── OPTICS
│   ├── SpectralClustering
│   └── ...
├── datasets
├── decomposition
├── ensemble
│   ├── AdaBoostClassifier
│   ├── AdaBoostRegressor
│   ├── BaggingClassifier
│   ├── BaggingRegressor
│   ├── GradientBoostingClassifier
│   ├── GradientBoostingRegressor
│   ├── RandomForestClassifier
│   ├── RandomForestRegressor
│   └── ...
├── feature_extraction
├── feature_selection
├── linear_model
│   ├── LinearRegression
│   ├── LogisticRegression
│   ├── Ridge
│   ├── Lasso
│   └── ...
├── metrics
├── model_selection
│   ├── cross_val_score
│   ├── train_test_split
│   ├── GridSearchCV
│   ├── RandomizedSearchCV
│   └── ...
├── naive_bayes
├── neighbors
│   ├── KNeighborsClassifier
│   ├── KNeighborsRegressor
│   └── ...
├── neural_network
│   ├── MLPClassifier
│   ├── MLPRegressor
│   └── ...
├── pipeline
├── preprocessing
│   ├── StandardScaler
│   ├── MinMaxScaler
│   ├── LabelEncoder
│   ├── OneHotEncoder
│   └── ...
├── svm
│   ├── SVC
│   ├── SVR
│   ├── LinearSVC
│   ├── LinearSVR
│   └── ...
├── tree
│   ├── DecisionTreeClassifier
│   ├── DecisionTreeRegressor
│   └── ...
└── utils
```

<br>

###### ↳ By referring to this hierarchy, can you please write an import statement for importing a Support Vector Classifier under the alias of `AwesomeSVC`?

```python
from sklearn.svm import SVC as AwesomeSVC

myClassifer = AwesomeSVC() # then it can be instantiated like this
```

It's a little bit confusing, but hopefully this clarifies the internal structure of `sklearn`. 

<br>

---

##### 

<br>

---

#####

<br>

---

#####

<br>

---

#####

<br>

---

#####

<br>

---

#####

<br>

---

#####

<br>

---

#####

<br>

---

#####

<br>

---

#####

<br>

---

#####

<br>

---

##### How does `StandardScalar()` work. 