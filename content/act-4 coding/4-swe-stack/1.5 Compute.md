We need more compute. 

---
##### What is compute? 

<br>

---

##### What is a parallel processing task? 

The key is **independence.** 

The best example are shaders. 
They are essentially mathematical functions which take a **two-dimensional** coordinate: `x, y` i.e the position of a pixel on your screen, and output a 3 or more dimensional vector describing the colour that specific pixel should be, `r, g, b`

$f(x, y) \to (r, g, b)$

This computation from **pixel position** to **colour** is most likely very simple, 

This is the type of function that we would like to compute in **parallel**, for every pixel on the screen. The reason we can do this is that in any given frame, we do not need to wait for the output of one pixel to calculate the colour of another. 

This is why GPU's use are used: they're great at doing a little calculation many many times simultaneously. CPU's on the other hand, are suited for tasks that...

<br>

---
##### Why is concurrency so important to machine learning?

<br>

---
##### Why are GPU's so import to machine learning? 

> [!check] Graphical Processing Unit (GPU)
> A graphics processing unit (GPU) is a specialized electronic circuit initially designed to accelerate computer graphics and image processing. 
> They contain **many** small, efficient **cores**. 


>After their initial design, GPUs were found to be useful for non-graphic calculations involving **embarrassingly parallel** problems due to their parallel structure. Other non-graphical uses include the training of neural networks and cryptocurrency mining.


---

This should go through k-fold cross validation, ROC cures, dendrographs? no that's in. What was that like how to reorder a heatmap thing yeah... 

<br>

---

There was something about bufferring and like bottlenecks