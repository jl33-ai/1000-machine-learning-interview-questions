`gnb = GaussianNB()`

###### (A) Why is it called 'naive' Bayes? 

https://scikit-learn.org/stable/modules/naive_bayes.html

[[(2.10) Multinomial Naive Bayes]]
#Logarithms
[[(1.3) Normal Distribution]]
[[Probability vs Likelihood]]

---

###### Imagine if you were trying to predict whether someone would like 'Attack on Titan' based on some features. How could you do it? 

The following features: 
`hair_colour`


Given some features and data: 
Fit a normal distribution to it, by 'fitting' mean and standard deviation. 

Fit distributions to each feature, for each class

Make an initial guess that they like it (prior probabilities)
Make an initial guess that they do not like it 

Then calculate likelihoods under a single given 

Multiply them together, then take logs (to prevent underflow)

Every computer has a limit to how close a number can get to 0 before it can no longer accurately keep track of that number. WE run into errors. Does it matter what log we use. 

- representation of all these floating points in computer memory are finite. 



