> [!quote]

---

##### What is a Support Vector Machine? 

> [!check] Non-Linearly Separable Data
> - The need for SVM's arises when dealing with non-linearly separable data - i.e data that you cannot separate with a [[(2.9.1) Support Vector Classifiers#What is a Hyperplane?|hyperplane]] (a line or plane)
> - A one-dimensional example:
> 
> <br>
> 
> ![[non-linear-separable.svg|250]]
> 
> 
> - A two-dimensional example
> 
> <br>
> 
> ![[1*JVZ4FXVRlr1oN-4ffq_kNQ.png|250]]

<br>

---
##### So then how do SVM's solve this? What's the main idea?

1. Start with data in a relatively **[[1.2 Easy Questions#What is a 'dimension' of data in ML|low dimension]]**


<br>


![[svm-steps.svg|300]]


<br>


2. Transform the data into a **[[1.2 Easy Questions#What is a 'dimension' of data in ML|higher dimension]]**

<br>


![[svm-steps-3.svg|300]]

<br>

3. Find a **[[(2.9.1) Support Vector Classifiers|Support Vector Classifiers]]** that separates the higher dimensional data into two groups

<br>

![[svm-steps-2.svg|300]]


<br>


###### ↳ Is it a supervised or unsupervised machine learning model?

They are definitely supervised. The decision boundary is derived directly from the training data. 



<br>

###### ↳ Are they only useful for classification? 


No! They can also be used for regression *(more on this later)*.

<br>


---

##### When would this type of data arise (i.e data that cannot be linearly separated)'

<br>

![[non-linear-separable.svg|250]]

<br>

☞ Imagine that the **x-axis** represents the `dosage` of a particular medicine. 
☞ The two classes would be `cured` or `not cured`.
☞ And the yellow dots in the middle would represent the ideal `dosage` of medicine that should be taken to cure the patient; to little or too much is ineffective. 

<br>

---

##### In the [[(2.9.2) Support Vector Machines#So then how do SVM's solve this? What's the main idea?|previous example]], each datapoint was squared to form the new dimension. But in practice, how can you determine the best transformation?

**This is true:** how did we know to create a new axis consisting of $\text{dosage}^2$, instead of $\text{dosage}^3$, or $\text{dosage}^{0.5}+33$? The answer is **kernal functions**

> [!check] Kernel Functions
> - SVM's use kernel functions to systematically find [[(2.9.1) Support Vector Classifiers|support vector classifiers]] in higher dimensions. 
> - These kernel functions transform the data in such a way that the data can then be separated by the simpler [[(2.9.1) Support Vector Classifiers|support vector classifiers]] using a flat [[(2.9.1) Support Vector Classifiers#What is a Hyperplane?|hyperplane]]. 
> - Note: there are many different types of kernel functions to pick from. Kernel functions are a class of functions

<br>

##### Could you name a commonly used kernel function? 

Yes, the **polynomial kernel**

> [!check] Polynomial kernel
> - $(x_1 * x_2 + r)^d$
> - It has two parameters
> 	- $r$ 
> 	- $d$ the degree of the polynomial 
> <br>
> The degree of the polynomial directly specifies the number of dimensions of the data. E.g, a 2 degree







<br>

---

##### What type of data are SVM's well suited for classifying? 

**Support Vector Machines** are also good for classifying: 
☞ Data that a neural net would overfit
☞ High dimensional data
☞ Non-linear data, using [[(2.9.2) Support Vector Machines#What do you do if|Kernel Tricks]]

<br>

---

##### Why would you use an SVM when neural networks exist? 

- If low amounts of high dimensional data.
- If it's data with clear segments, that neural nets are likely to overfit. 
- SVM's are lightweight whereas neural networks are computationally expensive.
- SVMs are simpler to implement and tune compared to neural networks, which require careful tuning of numerous hyperparameters and long training times.

> [!quote] Anonymous
> Everyone always jumps to neural networks, but often svms do the same classification work with no huge iterative training required and are simply a better solution much of the time.

<br>

---

##### What is the difference between a MMC, SVC, and a SVM? When should you use each? 

☞ **[[(2.9.1) Support Vector Classifiers#What is a Maximal Margin Classifier?|MMC]]:** If the data has no outliers or noise, and is linearly separable.
☞ **[[(2.9.1) Support Vector Classifiers|SVC]]:** If the data is linearly separable.
☞ **[[(2.9.2) Support Vector Machines#^What is a Support Vector Machine|SVM]]:** If the data is not linearly separable.

<br>

---

